---
title: "Life-Expectancy-Analysis"
author: "Milena Biernacka, Agata Dratwa"
date: '2023-05-19'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(corrplot)
library(caret)
```

Reading data:
```{r}
data <- read.csv("Life-Expectancy-Data.csv")
head(data)
dim(data)
str(data)
```

Dropping columns containing NA values:
```{r}
data <- na.omit(data)
dim(data)
```


Dropping columns 'Country' and 'Year':
```{r}
data <- data[, -c(2,1)]
head(data)
```
Correlation between numerical attributes:
```{r}
cor(data[,-1])
```
```{r}
corrplot(cor(data[,-1]), method = 'color')
```


### Building linear regression model:

Splitting data into training and testing sets:

```{r}
set.seed(213)
train_indices <- sample(nrow(data), nrow(data) * 0.8)
train_data <- data[train_indices, ]
test_data <- data[-train_indices, ]
```

```{r}
model <- lm(train_data$Life.expectancy ~ ., data = train_data)
```

```{r}
#model
#model$coefficients
```
```{r}
summary(model)
```

Based on p-value statistically significant are:

- Adult Mortality
- Infant deaths
- Alcohol
- Percentage expenditure
- BMI
- Under five deaths
- Total.expenditure 
- Diphtheria
- HIV AIDS
- Income
- Schooling

It means that we should remove other variables from our model.

Positive coefficients:

- Infant deaths
- Percentage expenditure
- Income
- Schooling
- Diphtheria
- Total.expenditure 
- BMI

Negative coefficients:

- Adult Mortality
- HIV AIDS
- Alcohol
- Under five deaths

### Evaluating linear regression model

```{r}
predictions <- predict(model, newdata = test_data)
```

```{r}
# Ewaluacja modelu

#mse
mse <- mean((predictions - test_data$Life.expectancy)^2)
#mae
mae <- mean(abs(predictions - test_data$Life.expectancy))
#R^2
ss_residual <- sum((test_data$Life.expectancy - predictions)^2)
ss_total <- sum((test_data$Life.expectancy - mean(test_data$Life.expectancy))^2)
r_squared <- 1 - (ss_residual / ss_total)

# Wyświetlanie wyników
cat("Mean Squared Error (MSE):", mse, "\n")
cat("Mean Absolute Error (MAE):", mae, "\n")
cat("R-squared:", r_squared, "\n")

```

### Building linear regression model with only significant variables

```{r}
model2 <- lm(train_data$Life.expectancy ~ Adult.Mortality + infant.deaths + Alcohol + percentage.expenditure +
              BMI + under.five.deaths + Total.expenditure + Diphtheria + HIV.AIDS + Income.composition.of.resources + Schooling,data = train_data)
```

```{r}
summary(model2)
```

All variables are statistically significant.

### Evaluating linear regression model with only significant values

```{r}
predictions2 <- predict(model2, newdata = test_data)
```

```{r}
# Ewaluacja modelu

#mse
mse <- mean((predictions2 - test_data$Life.expectancy)^2)
#mae
mae <- mean(abs(predictions2 - test_data$Life.expectancy))
#R^2
ss_residual <- sum((test_data$Life.expectancy - predictions2)^2)
ss_total <- sum((test_data$Life.expectancy - mean(test_data$Life.expectancy))^2)
r_squared <- 1 - (ss_residual / ss_total)

# Wyświetlanie wyników
cat("Mean Squared Error (MSE):", mse, "\n")
cat("Mean Absolute Error (MAE):", mae, "\n")
cat("R-squared:", r_squared, "\n")
```

Values of metrics are almost the same for both models. 

### Building logistic regression model
To conduct logistic regression, first we have to transform life_expectancy variable to binary one. If the value is above median of life expectancy, the binary value is 1, if below is 0.

```{r}
# Calculate the median of life expectancy
threshold <- mean(data$Life.expectancy)

# Create a new binary variable based on the median threshold
data$Life.expectancy.binary <- ifelse(data$Life.expectancy > threshold, 1, 0)
```

```{r}
# split hte data into training and testing
set.seed(213)
train_indices <- sample(nrow(data), nrow(data) * 0.8)
train_data <- data[train_indices, ]
test_data <- data[-train_indices, ]
```


```{r}
# Creating the logistic regression model
logistic_model <- glm(Life.expectancy.binary ~ . -Life.expectancy, data = train_data, family = binomial)
```


```{r}
# summary of the model
summary(logistic_model)
```
Based on p-value statistically significant are 10 variables from our model. Other variables we should remove to obtain better results
Variables statistically significant: 

- Adult Mortality
- Infant deaths
- Percentage expenditure
- Under five deaths
- Total.expenditure 
- HIV AIDS
- Income
- Schooling

Significant variables with positive coefficients:

- Infant Deaths
- thinness..1.19.years 
- Income
- Schooling  
- percentage.expenditure  

Variables with negative coefficients:

- Adult Mortality
- Under five deaths
- Total.expenditure 
- HIV AIDS
- thinness.5.9.years  

### Evaluating logistic regression model
```{r}
# Make predictions on the test set
probabilites <- predict(logistic_model, newdata = test_data, type = "response")
predictions <- ifelse(probabilites > 0.5, 1, 0)
```

```{r}

```

```{r}
# Create a confusion matrix
conf_matrix <- table(Actual = test_data$Life.expectancy.binary, Predicted = predictions)
```


```{r}
# Print the confusion matrix
print(conf_matrix)
```

```{r}
# Calculate accuracy
accuracy <- sum(predictions == test_data$Life.expectancy.binary) / length(predictions)
# Calculate precision
precision <- conf_matrix[2, 2] / sum(conf_matrix[, 2])
# Calculate recall
recall <- conf_matrix[2, 2] / sum(conf_matrix[2, ])
# Calculate F1-score
f1_score <- 2 * precision * recall / (precision + recall)
cat("Accuracy:", accuracy, "\n")
cat("Precision:", precision, "\n")
cat("Recall:", recall, "\n")
cat("F1-Score:", f1_score, "\n")
```
Conclusions:
The logistic regression model just predict if value is above or below the general median of life expectancy for whole world so the predictions are very accurate because we do not have predict specific value.

### Building logistic regression model with only significant variables

```{r}
# Creating the logistic regression model
logistic_model_2 <- glm(Life.expectancy.binary ~ Adult.Mortality + infant.deaths + percentage.expenditure +
                        under.five.deaths + Total.expenditure + HIV.AIDS +
                        thinness..1.19.years + Income.composition.of.resources + Schooling,
                      data = train_data, family = binomial)
```


```{r}
# summary of the model
summary(logistic_model_2)
```
### Evaluating logistic regression model with only signifcant values
```{r}
# Make predictions on the test set
probabilites <- predict(logistic_model_2, newdata = test_data, type = "response")
predictions <- ifelse(probabilites > 0.5, 1, 0)
```

```{r}
# Create a confusion matrix
conf_matrix <- table(Actual = test_data$Life.expectancy.binary, Predicted = predictions)
```

```{r}
# Print the confusion matrix
print(conf_matrix)
```

```{r}
# Calculate accuracy
accuracy <- sum(predictions == test_data$Life.expectancy.binary) / length(predictions)
# Calculate precision
precision <- conf_matrix[2, 2] / sum(conf_matrix[, 2])
# Calculate recall
recall <- conf_matrix[2, 2] / sum(conf_matrix[2, ])
# Calculate F1-score
f1_score <- 2 * precision * recall / (precision + recall)
cat("Accuracy:", accuracy, "\n")
cat("Precision:", precision, "\n")
cat("Recall:", recall, "\n")
cat("F1-Score:", f1_score, "\n")
```

The results are slightly with in comparison to model with all variables


